[package]
name = "xtask"
version = "0.0.0"
edition = "2021"
authors = ["YdrMaster <ydrml@hotmail.com>"]

# See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html

[dependencies]
common = { path = "../common" }
tensor = { path = "../tensor" }
causal-lm = { path = "../causal-lm" }
service = { path = "../service" }
web-api = { path = "../web-api" }

# models
llama = { path = "../models/llama/common" }
llama-cpu = { path = "../models/llama/common-cpu" }
llama-nv = { path = "../models/llama/nvidia-gpu", optional = true }
llama-nv-distributed = { path = "../models/llama/nvidia-gpu-distributed", optional = true }
llama-cn = { path = "../models/llama/cambricon-mlu", optional = true }
mixtral = { path = "../models/mixtral/common" }
mixtral-cpu = { path = "../models/mixtral/cpu" }
mixtral-nv = { path = "../models/mixtral/nvidia-gpu-distributed", optional = true }

digit-layout.workspace = true
log.workspace = true
tokio.workspace = true
simple_logger = "5.0"
colored = "2.1"
clap = { version = "4.5", features = ["derive"] }
time = "0.3"

[build-dependencies]
build-script-cfg.workspace = true
search-cuda-tools.workspace = true
search-neuware-tools.workspace = true

[features]
default = ["nvidia", "cambricon"]
nvidia = ["llama-nv", "llama-nv-distributed", "mixtral-nv"]
cambricon = ["llama-cn"]
